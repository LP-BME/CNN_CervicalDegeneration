{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic extensions\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# Import tensorflow imagedatagenerator\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.layers import SpatialDropout2D\n",
    "\n",
    "# Import toolboxes data and result processing\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training directory \n",
    "train_success = os.path.join('LUMC/NECK_preprocessed/Train_extra/Success')\n",
    "train_nosuccess = os.path.join('LUMC/NECK_preprocessed/Train_extra/NoSuccess_extra')\n",
    "\n",
    "train_success_raw = os.path.join('LUMC/Neck_01flexie_selected/Train_raw/Success')\n",
    "train_nosuccess_raw = os.path.join('LUMC/Neck_01flexie_selected/Train_raw/NoSuccess')\n",
    "\n",
    "# Testing directory\n",
    "test_success = os.path.join('LUMC/NECK_preprocessed/Test_extra/Success')\n",
    "test_nosuccess = os.path.join('LUMC/NECK_preprocessed/Test_extra/NoSuccess_extra')\n",
    "\n",
    "test_success_raw = os.path.join('LUMC/Neck_01flexie_selected/Test_raw/Success')\n",
    "test_nosuccess_raw = os.path.join('LUMC/Neck_01flexie_selected/Test_raw/NoSuccess')\n",
    "\n",
    "# Total datasets\n",
    "train_total = os.path.join('LUMC/NECK_preprocessed/Train_extra/')\n",
    "test_total = os.path.join('LUMC/NECK_preprocessed/Test_extra/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information from the data paths\n",
    "print('total number of training images with label success:', len(os.listdir(train_success)))\n",
    "print('total number of training images with label no success:', len(os.listdir(train_nosuccess)))\n",
    "\n",
    "print('total maps training images:', len(os.listdir(train_total)))\n",
    "print('total maps test images:', len(os.listdir(test_total)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image normalization by rescaling, as 255 is maximum pixel value, the value of the image will be between 0 an 1\n",
    "train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow of training images\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'LUMC/NECK_preprocessed/Train_extra/',      # Input directory for the training images \n",
    "        classes = ['Success', 'NoSuccess_extra'],   # Names of the directory folders, which work as labels\n",
    "        target_size=(200, 200),                     # Images from the data generator will be 200 by 200 pixels\n",
    "        batch_size=10,                              # Because of the limited input images\n",
    "        class_mode='binary',                        # Because of the binary classification tasks on the X-ray images\n",
    "        shuffle=True)            \n",
    "\n",
    "# Flow of test images\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "     #  'LUMC/NECK_preprocessed/Test_extra/',        # Input directory for the test images \n",
    "       'LUMC/Neck_01flexie_selected/Test_raw/',   \n",
    "        classes = ['Success', 'NoSuccess'],   # Names of the directory folders, which work as labels\n",
    "        target_size=(200, 200),                     # Images from the data generator will be 200 by 200 pixels\n",
    "        batch_size=10,                              # Because of the limited input images\n",
    "        class_mode='binary',                        # Because of the binary classification tasks on the X-ray images\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this part, the set-up of the actual convolutional neural network (CNN) model is described and programmed\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "\n",
    "# The first convolution layer\n",
    "tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
    "tf.keras.layers.BatchNormalization(),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Dropout(0.5),\n",
    "    \n",
    "# The second convolution\n",
    "tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Dropout(0.5),   \n",
    "    \n",
    "# The third convolution\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Dropout(0.5),   \n",
    "    \n",
    "# The fourth convolution\n",
    "tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "tf.keras.layers.MaxPooling2D(2,2),\n",
    "tf.keras.layers.Dropout(0.5),   \n",
    "\n",
    "# Flatten results to feed into the dense layer\n",
    "tf.keras.layers.Flatten(),\n",
    "\n",
    "# First dense layer\n",
    "tf.keras.layers.Dense(512, activation='relu'),\n",
    "\n",
    "# Dense output neuron\n",
    "tf.keras.layers.Dense(1, activation='sigmoid')])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()\n",
    "model.layers\n",
    "model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss, optimizer and metric determination\n",
    "# https://www.jeremyjordan.me/nn-learning-rate/\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend as K\n",
    "from keras.callbacks import Callback\n",
    "import numpy as np\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "def step_decay_schedule(initial_lr=1e-2, decay_factor=0.75, step_size=10):\n",
    " \n",
    "    def schedule(epoch):\n",
    "        return initial_lr * (decay_factor ** np.floor(epoch/step_size))\n",
    "    \n",
    "    return LearningRateScheduler(schedule)\n",
    "\n",
    "lr_sched = step_decay_schedule(initial_lr=1e-3, decay_factor=0.75, step_size=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam',  metrics=['accuracy'])\n",
    "#model.compile(loss='binary_crossentropy', optimizer=opt,  metrics=['accuracy'])\n",
    "\n",
    "# Settings for the training-process of the CNN model\n",
    "history = model.fit(train_generator,\n",
    "      steps_per_epoch=30,  \n",
    "      epochs=40, \n",
    "      callbacks=[lr_sched],\n",
    "      verbose=1,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accurracy validation\n",
    "model.evaluate(train_generator)\n",
    "model.evaluate(validation_generator)\n",
    "\n",
    "# Make predictions, based on the data generator flow from the input directory\n",
    "STEP_SIZE_TEST=validation_generator.n//validation_generator.batch_size\n",
    "validation_generator.reset()\n",
    "train_generator.reset()\n",
    "preds = model.predict(validation_generator,\n",
    "                      verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# False positive rate and true postive rate, based on the predictions\n",
    "fpr, tpr, _ = roc_curve(validation_generator.classes, preds)\n",
    "\n",
    "# Area under curve (AUC) calculation\n",
    "roc_auc = auc(fpr, tpr) \n",
    "\n",
    "#Plotting of the ROC curve\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange',\n",
    "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--', label='No Skill')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Performance per epoch (x-axis), expressed in accuracy and loss value (y-axis)\n",
    "\n",
    "# Model accuracy estimation\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction values\n",
    "preds = model.predict(validation_generator,\n",
    "                      verbose=1)\n",
    "#print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "s = 0; # Surgery success\n",
    "u = 0; # Unsure value\n",
    "n = 0; # No surgery success\n",
    "\n",
    "for i in range(0,len(preds)):\n",
    "    if preds[i]<0.50:\n",
    "      #  print(\"Surgery success\")\n",
    "        s=s+1\n",
    "        \n",
    "    else:\n",
    "     #   print(\"No surgery success: Person has no benefit from surgery\")\n",
    "        n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction value evaluation\n",
    "\n",
    "print(\"There are \" + str(s) + \" people predicted to have surgery success\")\n",
    "print(\"There are \" + str(n) + \" people predicted with no surgery success\")\n",
    "#print(\"There are \" + str(u) + \" people predicted with unsure prediction value\")\n",
    "\n",
    "# Probability evaluation \n",
    "#print(\"There are \" + str(a) + \" prediction with low probability, highly unsure\")\n",
    "#print(\"There are \" + str(b) + \" prediction with medium probability\")\n",
    "#print(\"There are \" + str(c) + \" prediction with high probability, very sure\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Denote as an external tool: source... \n",
    "# https://towardsdatascience.com/convolutional-neural-network-feature-map-and-filter-visualization-f75012a5a49c#:~:text=%20Visualizing%20Feature%20maps%20or%20Activation%20maps%20generated,Normalize%20the%20array%20by%20rescaling%20it%20More%20\n",
    "# https://www.analyticsvidhya.com/blog/2020/11/tutorial-how-to-visualize-feature-maps-directly-from-cnn-layers/\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n",
    "\n",
    "# No success images\n",
    "#img_path='LUMC/NECK_preprocessed/Test_extra/NoSuccess_extra/01_0574189_rotated_min15_resized_cropped_rotated_extra2.png'#whole cervical spine. 52_xray_resized_cropped.png doet het goed\n",
    "#img_path='LUMC/NECK_preprocessed/Test_extra/NoSuccess_extra/01_0356963_rotated_min10_resized_cropped.png'#whole cervical spine. 52_xray_resized_cropped.png doet het goed\n",
    "#img_path='LUMC/NECK_preprocessed/Test_extra/NoSuccess_extra/01_0769096_rotated_min15_resized_cropped.png'#whole cervical spine. 52_xray_resized_cropped.png doet het goed\n",
    "\n",
    "# Success images\n",
    "#img_path='LUMC/NECK_preprocessed/Test_extra/Success/01_1508719_rotated_min10_resized_cropped.png'\n",
    "img_path='LUMC/NECK_preprocessed/Test_extra/Success/01_1646004_rotated_min10_resized_cropped.png'\n",
    "\n",
    "#plt.imshow('LUMC/Resized_cropped/Train/Degeneration/87_xray_resized_cropped.png')\n",
    "\n",
    "# Output= intermediate representations for all layers in the model\n",
    "successive_outputs = [layer.output for layer in model.layers[1:]]\n",
    "\n",
    "#visualization_model = Model(img_input, successive_outputs)\n",
    "visualization_model = tf.keras.models.Model(inputs = model.input, outputs = successive_outputs)\n",
    "\n",
    "#Load the input image\n",
    "img = load_img(img_path, target_size=(200, 200))\n",
    "\n",
    "# Convert the xray image to an array with dimension 200,200,3\n",
    "xray   = img_to_array(img)                           \n",
    "xray   = xray.reshape((1,) + xray.shape)\n",
    "\n",
    "# Rescale by 1/255\n",
    "xray /= 255.0\n",
    "\n",
    "# Let's run input image through our vislauization network\n",
    "# to obtain all intermediate representations for the image.\n",
    "successive_feature_maps = visualization_model.predict(xray)\n",
    "\n",
    "# Retrieve are the names of the layers, so can have them as part of our plot\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
    "  print(feature_map.shape)\n",
    "  if len(feature_map.shape) == 4:\n",
    "    \n",
    "    # Plot Feature maps for the conv / maxpool layers, not the fully-connected layers\n",
    "   \n",
    "    n_features = feature_map.shape[-1]  # number of features in the feature map\n",
    "    size       = feature_map.shape[ 1]  # feature map shape (1, size, size, n_features)\n",
    "    \n",
    "    # We will tile our images in this matrix\n",
    "    display_grid = np.zeros((size, size * n_features))\n",
    "    \n",
    "    # Postprocess the feature to be visually palatable\n",
    "    for i in range(n_features):\n",
    "      xray  = feature_map[0, :, :, i]\n",
    "      xray -= xray.mean()\n",
    "      xray /= xray.std ()\n",
    "      xray *=  64 #Contrast of the images, the higher, the more contrast\n",
    "      xray += 128 #Clarity of the images\n",
    "      xray  = np.clip(xray, 0, 255).astype('uint8')\n",
    "      \n",
    "    # Tile each filter into a horizontal grid\n",
    "      display_grid[:, i * size : (i + 1) * size] = xray\n",
    "        \n",
    "        \n",
    "# Display the grid\n",
    "    scale = 20. / n_features\n",
    "    plt.figure( figsize=(scale * n_features, scale) )\n",
    "    plt.title ( layer_name )\n",
    "    plt.grid  ( False )\n",
    "    plt.imshow( display_grid, aspect='auto', cmap='viridis' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Iterate thru all the layers of the model\n",
    "for layer in model.layers:\n",
    "    if 'conv' in layer.name:\n",
    "        weights, bias= layer.get_weights()\n",
    "        print(layer.name)\n",
    "      #  print(layer.weights)\n",
    "        \n",
    "        #normalize filter values between  0 and 1 for visualization\n",
    "        f_min, f_max = weights.min(), weights.max()\n",
    "        filters = (weights - f_min) / (f_max - f_min)  \n",
    "        print(layer.name, filters.shape[3])\n",
    "        filter_cnt=1\n",
    "        \n",
    "        #plotting all the filters\n",
    "        for i in range(filters.shape[3]):\n",
    "            #get the filters\n",
    "            filt=filters[:,:,:, i]\n",
    "            #plotting each of the channel, color image RGB channels\n",
    "            for j in range(filters.shape[0]):\n",
    "                ax= plt.subplot(filters.shape[3], filters.shape[0], filter_cnt  )\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "                plt.imshow(filt[:,:, j])\n",
    "                filter_cnt+=1\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_layer_biases  = model.layers[0].get_weights()[1]\n",
    "second_layer_weights = model.layers[1].get_weights()[0]\n",
    "second_layer_biases  = model.layers[1].get_weights()[1]\n",
    "\n",
    "conv1_weights = model.layers[0].get_weights()[0]\n",
    "conv2_weights = model.layers[1].get_weights()[1]\n",
    "#conv3_weights = model.layers[2].get_weights()[2]\n",
    "#conv4_weights = model.layers[3].get_weights()[3]\n",
    "\n",
    "print(conv1_weights)\n",
    "print(conv2_weights)\n",
    "#print(conv3_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "success_generator = validation_datagen.flow_from_directory(\n",
    "       'LUMC/NECK_preprocessed/Test_extra/',        # Input directory for the test images \n",
    "        classes=['Success'],\n",
    "        target_size=(200, 200),                     # Images from the data generator will be 200 by 200 pixels\n",
    "        batch_size=10,                              # Because of the limited input images\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_success_generator =  validation_datagen.flow_from_directory(\n",
    "       'LUMC/NECK_preprocessed/Test_extra/',        # Input directory for the test images \n",
    "        classes=['NoSuccess_extra'],\n",
    "        target_size=(200, 200),                     # Images from the data generator will be 200 by 200 pixels\n",
    "        batch_size=10,                              # Because of the limited input images\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "succ_pred = model.predict(success_generator)\n",
    "nosucc_pred = model.predict(no_success_generator)\n",
    "\n",
    "succ_pred_arr = np.round(succ_pred)\n",
    "#print(succ_pred_arr)\n",
    "succ_pred_amount = sum(succ_pred_arr)\n",
    "succ_pred_amount_not = len(succ_pred_arr) - succ_pred_amount\n",
    "\n",
    "print('Amount that was classified as 1 in the success folder = ', int(succ_pred_amount))\n",
    "print('Amount that was classified as 0 in the success folder = ', int(succ_pred_amount_not))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_succ_pred_arr = np.round(nosucc_pred)\n",
    "no_succ_pred_amount = sum(no_succ_pred_arr)\n",
    "no_succ_pred_amount_not = len(no_succ_pred_arr) - no_succ_pred_amount\n",
    "\n",
    "print('Amount that was classified as 1 in the no success folder = ', int(no_succ_pred_amount))\n",
    "print('Amount that was classified as 0 in the no success folder = ', int(no_succ_pred_amount_not))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Success folder is in het echt 0\n",
    "#No succes folder is een 1\n",
    "\n",
    "cf_matrix = ([[int(succ_pred_amount_not), int(succ_pred_amount)],\n",
    "       [int(no_succ_pred_amount_not), int(no_succ_pred_amount)]])\n",
    "\n",
    "import seaborn as sns\n",
    "ax= plt.subplot()\n",
    "sns.heatmap(cf_matrix, annot=True,fmt='.0f', cmap='Blues', ax = ax)\n",
    "\n",
    "#Labels of the axes\n",
    "ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
    "ax.set_title('Confusion Matrix'); \n",
    "ax.xaxis.set_ticklabels(['Success', 'No Success']); ax.yaxis.set_ticklabels(['Success', 'No Success']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import *\n",
    "\n",
    "cf_matrix\n",
    "\n",
    "success_total = (succ_pred_amount_not)+(succ_pred_amount)\n",
    "nosuccess_total = (no_succ_pred_amount)+(no_succ_pred_amount_not)\n",
    "\n",
    "print('True positive rate TP = ', int(succ_pred_amount_not)/(success_total))\n",
    "print('True negative rate TN = ', int(no_succ_pred_amount)/((nosuccess_total)))\n",
    "print('False positive rate FP = ', int(no_succ_pred_amount_not)/((nosuccess_total)))\n",
    "print('False negative rate FN = ', int(succ_pred_amount)/((success_total)))\n",
    "\n",
    "TP = (succ_pred_amount_not)/(success_total)\n",
    "TN = (no_succ_pred_amount)/(nosuccess_total)\n",
    "FP = (no_succ_pred_amount_not)/(nosuccess_total)\n",
    "FN = (succ_pred_amount)/(success_total)\n",
    "\n",
    "print('Positive predictive value (=precision?)= ', (TP)/((TP) + (FP)))\n",
    "print('Negative predictive value = ', (TN)/((FN) + (TN)))\n",
    "print('Sensitivity (=recall?)= ', (TP)/((TP) + (FN)))\n",
    "print('Specificity = ', (TN)/((FP) + (TN)))\n",
    "\n",
    "print('Precision= ', (TP)/((TP) + (FP)))\n",
    "print('Recall= ', (TP)/((TP) + (FN)))\n",
    "\n",
    "precision = (TP)/((TP) + (FP))\n",
    "recall = (TP)/((TP) + (FN))\n",
    "\n",
    "F1 = ((2*(precision)*(recall))/((precision)+(recall)))\n",
    "print('F1 score = ', F1)\n",
    "\n",
    "MCC = ((TP*TN)-(FP*TN))/(sqrt((TP+FP)*(TP+FN)*(TN+FP)*(TN+FN)))\n",
    "print('Matthews correlation coefficient MCC = ', MCC)\n",
    "\n",
    "accuracy = ((TP+TN)/((TP+FN+TN+FP)))\n",
    "print('Overall accuracy based on CM = ', accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "print(sys.version)\n",
    "print(sys.version_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputest",
   "language": "python",
   "name": "gputest"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
